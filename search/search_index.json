{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Genome Data Project: Overview","text":"<p>Welcome to the project documentation!</p> <p>The goal of this project is to analyze, simplify, and structure genetic sequence data\u2014particularly small non-coding RNAs\u2014for further analysis. Semantic technologies such as Wikibase and SPARQL are utilized as part of this workflow.</p>"},{"location":"#what-can-you-find-in-this-repository","title":"What can you find in this repository?","text":"<ul> <li>Documentation \u2013 Project description, presentations, and accompanying texts</li> <li>Preprocessing scripts \u2013 Tools for sequence processing and simplification</li> <li>SPARQL queries \u2013 Queries for targeted information retrieval</li> <li>Database snapshots \u2013 Before/after versions of the databases used</li> <li>Paper \u2013 Reference article: PMC3531160</li> <li>License \u2013 Information about the use of the contents</li> </ul>"},{"location":"#what-this-documentation-covers","title":"What this documentation covers","text":"<ul> <li>Origin and selection of the data</li> <li>Data processing and analysis</li> <li>Visualizations and presentation decisions</li> <li>Project objectives and outlook</li> </ul>"},{"location":"about/","title":"About the Project","text":""},{"location":"about/#objective","title":"Objective","text":"<p>The project analyzes genetic sequence data with a focus on small non-coding RNAs. The aim is to represent biological complexity in a structured, machine-readable form and to explore new approaches for data reduction, visualization, and querying.</p>"},{"location":"about/#why-simplified-sequence-representation","title":"Why Simplified Sequence Representation?","text":"<p>Because RNA sequences are often very long and difficult to read, a full representation is deliberately omitted during preprocessing. Instead, descriptions are provided through features such as base count, in order to convey relevant information more compactly.</p>"},{"location":"about/#methods-and-technologies","title":"Methods and Technologies","text":"<ul> <li>Wikibase Cloud instance for structured storage</li> <li>SPARQL for targeted queries (e.g., \"all instances of small non-coding RNA\")</li> <li>Preprocessing with Python to shorten/normalize sequences</li> <li>Reference databases: including Rfam</li> </ul>"},{"location":"about/#project-timeline","title":"Project Timeline","text":"<ul> <li>Start date: 11.12.2024 (topic selection)</li> <li>First repo setup: Week of 08.01.2025</li> <li>Regular meetings: with Ms. Scharf and Mr. F\u00f6rster</li> <li>Final phase: May\u2013June 2025</li> <li>Submission: 30.06.2025</li> </ul>"},{"location":"about/#team-collaboration","title":"Team &amp; Collaboration","text":"<ul> <li>GitHub collaboration via private repository</li> <li>Members: Rayan Al-Jaf, Semih Akbas</li> <li>Exchange via regular meetings &amp; shared repository structure</li> </ul>"},{"location":"analysis/","title":"Processing &amp; Analysis","text":""},{"location":"analysis/#data-processing","title":"Data Processing","text":"<ul> <li>Parsing of FASTA files</li> <li>Generation of sequence statistics</li> <li>Pattern recognition</li> <li>Classification by strand orientation</li> </ul>"},{"location":"analysis/#crunching-with-python","title":"Crunching with Python","text":"<p>Tools: <code>pandas</code></p> <p>Examples:</p> <ul> <li>Sequence length</li> <li>Nucleotide composition (A, T, C, G)</li> </ul>"},{"location":"analysis/#sequence-simplification-export","title":"Sequence Simplification &amp; Export","text":""},{"location":"analysis/#simplified-representation-instead-of-full-sequence","title":"Simplified Representation Instead of Full Sequence","text":"<ul> <li>Complete RNA sequences are often several thousand bases long   Not suitable for Wikibase integration \u2192 decision for a shortened representation</li> <li>Instead: storage of length, base frequency, ID, type</li> </ul>"},{"location":"analysis/#export-to-wikibase-cloud-instance","title":"Export to Wikibase Cloud Instance","text":"<ul> <li>Structured items: RNA, organism, length, strand, type</li> <li> <p>SPARQL queries enable, for example:</p> </li> <li> <p>All RNAs of a specific organism</p> </li> <li>Filtering by length ranges or RNA type</li> </ul>"},{"location":"dataprep/","title":"Data Preparation","text":"<p>This document outlines the main steps of extracting and preparing genetic sequence data for further analysis in the project.</p>"},{"location":"dataprep/#what-do-we-do-with-the-data","title":"What Do We Do With the Data?","text":""},{"location":"dataprep/#extraction","title":"Extraction","text":"<ul> <li>ID</li> <li>Gene name</li> <li>Positions (start &amp; end)</li> <li>Strand orientation (forward / reverse)</li> <li>Sequence (for length and base composition)</li> </ul>"},{"location":"dataprep/#structuring","title":"Structuring","text":"<ul> <li>The extracted information is stored in formats such as <code>.csv</code> for further processing and integration.</li> </ul>"},{"location":"dataprep/#preprocessing-steps","title":"Preprocessing Steps","text":"<ul> <li>Parsing: Automated parsing of FASTA files to extract relevant fields.</li> <li>Filtering: Removal of incomplete or duplicate entries.</li> <li>Feature Calculation: Calculation of sequence length and nucleotide composition (A, T, C, G).</li> <li>Data reduction: For downstream analyses and Wikibase integration, only summary features (length, base counts, etc.) are stored instead of full sequences.</li> </ul>"},{"location":"dataprep/#example-output","title":"Example Output","text":"ID Gene name Start End Strand Length A T C G xyz123 ffs 12345 12456 forward 112 32 28 25 27 <p>For further details on tools and integration, see the respective documentation files in the repository.</p>"},{"location":"datasources/","title":"Data Sources","text":""},{"location":"datasources/#where-does-the-data-come-from","title":"Where Does the Data Come From?","text":"<p>The genetic data comes from a bioinformatics database provided by a former colleague of Ms. Scharf.</p> <p>The format is FASTA\u2014a common text-based format for representing biological sequences.</p> <p>A brief look at the database:</p> ID Host organism Regulate Start End Strand Sequence saac123.1 Alicyclobacillus acidocaldarius subsp. acidocaldarius DSM 446 ffs 122685 122803 forward CCAAATCCTGATTGGGTCCCGCGCGGCGAAAACTCCCGAACCGTGTCAGGTCCTGACGGAAGCAGCACTAAGGGAGACCTTTCGGGCGACGCGGGGGTGCCTGATCGGGGTTTGGTTCA saac2021.1 Alicyclobacillus acidocaldarius subsp. acidocaldarius DSM 446 rnpB 2020892 2021289 reverse GAAGTAAGCCGGGCAATCGCCGGTGCGAGCCGCGAGGCTGCACGGGAGGAAAGTCCGAGCTCCACAGGGCAGGGTGCCGGATAACGTCCGGCGAGAGCGATCTCAGGGAAAGTGCCACAGAAATGCAGACCGCCGATGGCTCATACGAGCACAGGCAAGGGTGCAACGGTGCGGTAAGAGCGCACCAGCAGTCCGGAGACGGGCTGGCTAGGTAAACCCCACCCGGAGCAAGACCAAGTAGGGGCGCAGATGCGGTGGCCCGCCGCGCGCCCGGGTTGGTCGCTGGAGCCGGCTGGCAACAGTCGGCCTAGATAGATGATTGCCACTCCACATGTGCGAGGCGTCACGCCGCTTGCAGCACAGGAGGACAGAACTCGGCTTACAGGCTTGCTTCTTCG"},{"location":"goals/","title":"Long-term Project Goals","text":"<p>This file outlines the overarching goals of the project\u2014both in terms of biological insights and the development of methodological and technical approaches.</p>"},{"location":"goals/#1-biological-insights","title":"1. Biological Insights","text":"<p>The project aims to generate new knowledge about the biological significance of non-coding RNAs. This includes:</p> <ul> <li>Analysis of specific gene functionalities</li> </ul> <p>For example, the gene <code>rnpB</code>, which plays a key role in RNA processing.</p> <ul> <li>Investigation of strand orientation</li> </ul> <p>How does the reading direction influence gene expression and regulatory processes?</p> <ul> <li>Systematic classification of sRNAs</li> </ul> <p>Which functional groups can be identified, and how frequently do they occur in specific organisms?</p>"},{"location":"goals/#2-method-development","title":"2. Method Development","text":"<p>In addition to biological questions, the project is focused on advancing sustainable methodological approaches:</p> <ul> <li>Automated processing pipelines</li> </ul> <p>Development of robust scripts for processing, filtering, and standardizing genetic sequence data.</p> <ul> <li>Structuring &amp; integration into semantic systems (e.g., Wikibase Cloud)</li> </ul> <p>Transformation of raw biological data into structured, linked knowledge systems to enable better querying and analysis.</p> <ul> <li>Establishment of a relational database / knowledge base</li> </ul> <p>This enables queries such as \u201cShow all small non-coding RNAs in E. coli with more than 80 bases\u201d.</p> <ul> <li>Linking with external data sources</li> </ul> <p>Integration of reference data from Rfam, NCBI, or organism-specific databases.</p>"},{"location":"insights/","title":"Project Insights","text":"<p>This file documents key findings, experiences, and outcomes from our genome data project.</p>"},{"location":"insights/#1-what-was-tried","title":"1. What Was Tried","text":"<p>During the project, we experimented with various approaches and technologies to process and analyze genetic sequence data:</p> <ul> <li>Connection between Pywikibot and Wikibase to upload the dataset to the Wikibase API</li> <li>Automated connection to the Wikibase API for data integration using Wikibase-CLI and various bash scripts</li> <li>Development of custom preprocessing scripts in Python for sequence normalization and simplification</li> <li>Creation of SPARQL queries for targeted data extraction</li> </ul>"},{"location":"insights/#2-what-was-used","title":"2. What Was Used","text":"<p>The following tools and methods were used for the implementation of the project:</p> <ul> <li> <p>Python libraries:</p> </li> <li> <p><code>pandas</code> for data manipulation</p> </li> <li> <p>Wikibase Cloud instance as the central knowledge base</p> </li> <li> <p>Bash Scripting to create custom upload scripts for the Wikibase-API</p> </li> <li> <p>SPARQL for complex data queries</p> </li> <li> <p>GitHub for version control and team coordination</p> </li> <li> <p>Regular meetings with supervisors for alignment and feedback</p> </li> </ul>"},{"location":"insights/#3-what-worked-well","title":"3. What Worked Well","text":"<ul> <li>The preprocessing scripts reliably read and processed the sequences</li> <li>SPARQL queries provided accurate and targeted results for data analysis</li> <li>Wikibase-cli worked well for creating and editing entries via the shell, although uploading nearly 40,000 records took several hours</li> </ul>"},{"location":"insights/#4-what-didnt-work","title":"4. What Didn\u2019t Work","text":"<ul> <li>Difficulties with the automated connection between pywikibot and the Wikibase API caused delays and increased workload</li> <li>Storing complete RNA sequences in the knowledge base was not practical due to the data volume</li> <li>QuickStatements failed because commands were too long and caused the tool to freeze and in general just weren't as reliable as using bash scripts paired with wikibase-cli</li> <li>Creating Properties as basic Datatypes didnt work with the basic SPARQL Queries and therefore had to be changed to Wikibase-items</li> <li>Upload of all 40000 Items didnt work, due to multiple connection errors during the running code</li> <li>Sometimes claims for each Items werent set correctly, leading to an incosistency in the instance</li> </ul>"},{"location":"insights/#5-technical-challenges-solutions","title":"5. Technical Challenges &amp; Solutions","text":"<p>During the integration of data into Wikibase, several tools and approaches were tested:</p> <ul> <li>Pywikibot was initially used, but failed since it could not establish a connection to the Wikibase API.</li> <li>QuickStatements was also attempted, but the commands were too long for the tool and caused it to hang or crash.</li> <li>The final and successful solution was Wikibase-cli. This tool allowed for the creation and editing of entries directly via the shell. The only downside was that uploading nearly 40,000 entries required several hours and also failed in the end. Claims werent set correctly</li> </ul>"},{"location":"tools/","title":"Tools and Technologies Used","text":"<p>This file lists all tools and libraries utilized throughout the project, including a brief description of their function and areas of application.</p>"},{"location":"tools/#programming-language-libraries","title":"Programming Language &amp; Libraries","text":""},{"location":"tools/#python","title":"Python","text":"<p>The main programming language for data processing.</p>"},{"location":"tools/#python-libraries-used","title":"Python Libraries Used:","text":"<ul> <li>pandas   For tabular data processing and statistical analysis.</li> </ul>"},{"location":"tools/#database-semantic-technologies","title":"Database &amp; Semantic Technologies","text":""},{"location":"tools/#wikibase-cloud","title":"Wikibase Cloud","text":"<p>Used for structured storage of genetic data. Also served as the platform for SPARQL queries.</p> <ul> <li> <p>SPARQL   Query language for extracting specific information from the Wikibase instance.</p> </li> <li> <p>Wikibase API   Intended for automated population and maintenance of the database; worked only partially (see Insights).</p> </li> </ul>"},{"location":"tools/#version-control","title":"Version Control","text":""},{"location":"tools/#git-github","title":"Git &amp; GitHub","text":"<p>Used for versioning code, data, and documentation. GitHub also served for team coordination and presenting the repository.</p>"},{"location":"tools/#data-sources","title":"Data Sources","text":"<ul> <li> <p>FASTA files   Contained raw data, consisting of DNA/RNA sequences (e.g., from Rfam.org).</p> </li> <li> <p>Scientific paper   Used as a technical reference and background:   PMC3531160</p> </li> </ul>"},{"location":"tools/#additional-tools","title":"Additional Tools","text":"<ul> <li> <p>Markdown   For creating project documentation (README, Insights, Tools, etc.).</p> </li> <li> <p>GitHub Pages   For publishing and navigating the project documentation.</p> </li> </ul>"}]}